#!/usr/bin/env python3
"""
LLM System Status and Configuration Summary
Shows the current state of prompt injection and conversation management implementation.
"""
import sys
import os
from pathlib import Path
import sqlite3
import json

# Add aws_microservices to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "aws_microservices"))

try:
    from prompt_loader import prompt_loader
    from conversation_manager import ConversationManager
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("Make sure you're running this from the correct directory")
    sys.exit(1)

class LLMSystemSummary:
    """Generate comprehensive summary of LLM system status"""
    
    def __init__(self):
        """Initialize the summary generator"""
        self.base_dir = Path(__file__).parent.parent.parent
        self.prompts_dir = self.base_dir / "docs" / "prompts"
        self.conversation_manager = ConversationManager()
        
        print("üìä LLM System Status and Configuration Summary")
        print("=" * 65)
    
    def show_prompt_system_status(self):
        """Show prompt injection system status"""
        print("\nüéØ Prompt Injection System Status")
        print("-" * 40)
        
        # Check prompts directory
        if self.prompts_dir.exists():
            prompt_files = list(self.prompts_dir.glob("*.txt"))
            print(f"üìÅ Prompts directory: {self.prompts_dir}")
            print(f"üìÑ Found {len(prompt_files)} prompt files:")
            
            total_chars = 0
            for prompt_file in prompt_files:
                try:
                    content = prompt_file.read_text(encoding='utf-8')
                    char_count = len(content)
                    total_chars += char_count
                    print(f"    ‚úÖ {prompt_file.name}: {char_count:,} characters")
                except Exception as e:
                    print(f"    ‚ùå {prompt_file.name}: Error reading - {e}")
            
            print(f"üìä Total prompt content: {total_chars:,} characters")
            
            # Test prompt loading
            print(f"\nüîç Testing Prompt Loading:")
            call_types = ["inbound", "outbound", None]
            for call_type in call_types:
                call_type_desc = call_type if call_type else "general"
                try:
                    system_prompt = prompt_loader.get_system_prompt(call_type=call_type)
                    if system_prompt:
                        print(f"    ‚úÖ {call_type_desc}: {len(system_prompt):,} characters loaded")
                    else:
                        print(f"    ‚ö†Ô∏è  {call_type_desc}: No prompt loaded")
                except Exception as e:
                    print(f"    ‚ùå {call_type_desc}: Error - {e}")
        else:
            print(f"‚ùå Prompts directory not found: {self.prompts_dir}")
    
    def show_conversation_database_status(self):
        """Show conversation database status"""
        print(f"\nüí¨ Conversation Database Status")
        print("-" * 40)
        
        db_path = self.conversation_manager.db_path
        print(f"üóÑÔ∏è  Database path: {db_path}")
        
        if os.path.exists(db_path):
            print(f"‚úÖ Database file exists")
            
            try:
                # Check database contents
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # Check conversations table
                cursor.execute("SELECT COUNT(*) FROM conversations")
                conversation_count = cursor.fetchone()[0]
                print(f"üìä Total conversations: {conversation_count}")
                
                if conversation_count > 0:
                    cursor.execute("""
                        SELECT customer_phone, created_at, 
                               (SELECT COUNT(*) FROM messages WHERE conversation_id = conversations.conversation_id) as message_count
                        FROM conversations 
                        ORDER BY created_at DESC 
                        LIMIT 5
                    """)
                    recent_conversations = cursor.fetchall()
                    print(f"üïê Recent conversations:")
                    for phone, created_at, msg_count in recent_conversations:
                        print(f"    üìû {phone}: {msg_count} messages ({created_at})")
                
                # Check messages table
                cursor.execute("SELECT COUNT(*) FROM messages")
                message_count = cursor.fetchone()[0]
                print(f"üí¨ Total messages: {message_count}")
                
                conn.close()
                
            except Exception as e:
                print(f"‚ùå Database query error: {e}")
        else:
            print(f"‚ö†Ô∏è  Database file does not exist (will be created on first use)")
    
    def show_llm_service_status(self):
        """Show LLM service integration status"""
        print(f"\nüß† LLM Service Integration Status")
        print("-" * 40)
        
        services = [
            ("Mistral LLM", "localhost:8021", "aws_microservices/llm_mistral_service.py"),
            ("GPT LLM", "localhost:8022", "aws_microservices/llm_gpt_service.py")
        ]
        
        for service_name, endpoint, file_path in services:
            service_file = self.base_dir / file_path
            
            print(f"üéØ {service_name} ({endpoint})")
            
            if service_file.exists():
                print(f"    ‚úÖ Service file exists: {file_path}")
                
                # Check for key integrations
                try:
                    content = service_file.read_text(encoding='utf-8')
                    
                    integrations = {
                        "prompt_loader import": "from prompt_loader import prompt_loader",
                        "conversation_manager import": "from conversation_manager import ConversationManager", 
                        "conversation_id parameter": "conversation_id: Optional[str]",
                        "customer_phone parameter": "customer_phone: Optional[str]",
                        "get_system_prompt call": "prompt_loader.get_system_prompt",
                        "conversation tracking": "conversation_manager.add_message"
                    }
                    
                    for integration_name, search_text in integrations.items():
                        has_integration = search_text in content
                        status = "‚úÖ" if has_integration else "‚ùå"
                        print(f"    {status} {integration_name}")
                        
                except Exception as e:
                    print(f"    ‚ùå Error checking file: {e}")
            else:
                print(f"    ‚ùå Service file not found: {file_path}")
            
            print()
    
    def show_testing_capabilities(self):
        """Show available testing capabilities"""
        print(f"\nüß™ Testing Capabilities")
        print("-" * 40)
        
        test_scripts = [
            ("LLM Conversation System Test", "scripts/utilities/test_llm_conversation_system.py"),
            ("Enhanced Service Manager", "aws_microservices/enhanced_service_manager.py"),
            ("Conversation Manager Test", "scripts/utilities/test_conversation_manager.py"),
            ("Prompt Loader Test", "scripts/utilities/test_prompt_loader.py")
        ]
        
        for test_name, test_path in test_scripts:
            full_path = self.base_dir / test_path
            exists = "‚úÖ" if full_path.exists() else "‚ùå"
            print(f"    {exists} {test_name}: {test_path}")
    
    def show_implementation_summary(self):
        """Show high-level implementation summary"""
        print(f"\nüéâ Implementation Summary")
        print("-" * 40)
        
        features = [
            "‚úÖ Prompt injection system with automatic .txt file loading",
            "‚úÖ Call type differentiation (inbound/outbound/general)",
            "‚úÖ SQLite-based conversation database for context tracking", 
            "‚úÖ Enhanced LLM APIs with conversation_id and customer_phone",
            "‚úÖ Conversation context awareness to prevent repeated introductions",
            "‚úÖ Alex banking specialist persona with 7,687 character system prompt",
            "‚úÖ Independent LLM testing capability in service manager",
            "‚úÖ Both Mistral and GPT services enhanced with conversation management"
        ]
        
        for feature in features:
            print(f"  {feature}")
        
        print(f"\nüí° Next Steps:")
        print(f"  1. Restart LLM services to activate new conversation management code")
        print(f"  2. Test complete system with: python scripts/utilities/test_llm_conversation_system.py")
        print(f"  3. Use Enhanced Service Manager menu option 9 ‚Üí 3 for LLM-only testing")
        print(f"  4. Validate conversation continuity prevents repeated Alex introductions")
    
    def generate_complete_summary(self):
        """Generate complete system summary"""
        print(f"\nüöÄ Generating Complete LLM System Summary")
        print("=" * 70)
        
        self.show_prompt_system_status()
        self.show_conversation_database_status()
        self.show_llm_service_status()
        self.show_testing_capabilities()
        self.show_implementation_summary()
        
        print(f"\n‚úÖ LLM System Summary Complete!")
        print("=" * 70)

def main():
    """Main summary execution"""
    try:
        summary = LLMSystemSummary()
        summary.generate_complete_summary()
    except Exception as e:
        print(f"‚ùå Summary generation error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
