#!/usr/bin/env python3
"""
Interactive Pipeline Tester
============================

Interactive test menu for testing specific service combinations:
1. Select which services to test (STT, LLM, TTS)
2. Choose individual pipeline components or full pipeline
3. Test only what you want to test
4. Detailed error reporting for debugging

Usage:
    python tests/test_interactive_pipeline.py
"""

import asyncio
import sys
import time
import json
import base64
import requests
import pyaudio
import wave
import threading
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
import traceback
from contextlib import contextmanager

from contextlib import contextmanager

def chunk_text_intelligently(text: str, max_chunk_size: int = 2800) -> List[str]:
    """
    Split text into chunks that respect sentence boundaries and stay under max_chunk_size.
    Leaves some buffer under the 3000 character limit for safety.
    """
    if len(text) <= max_chunk_size:
        return [text]
    
    chunks = []
    remaining_text = text
    
    while remaining_text:
        if len(remaining_text) <= max_chunk_size:
            chunks.append(remaining_text.strip())
            break
        
        # Find the best split point (sentence boundary)
        chunk = remaining_text[:max_chunk_size]
        
        # Look for sentence endings (., !, ?) followed by space or newline
        best_split = -1
        for i in range(len(chunk) - 1, max(0, len(chunk) - 200), -1):
            if chunk[i] in '.!?' and i + 1 < len(chunk) and chunk[i + 1] in ' \n\t':
                best_split = i + 1
                break
        
        # If no sentence boundary found, look for other good split points
        if best_split == -1:
            for i in range(len(chunk) - 1, max(0, len(chunk) - 100), -1):
                if chunk[i] in ',;:' and i + 1 < len(chunk) and chunk[i + 1] in ' \n\t':
                    best_split = i + 1
                    break
        
        # If still no good split point, look for word boundaries
        if best_split == -1:
            for i in range(len(chunk) - 1, max(0, len(chunk) - 50), -1):
                if chunk[i] == ' ':
                    best_split = i + 1
                    break
        
        # If no word boundary, just split at max size (shouldn't happen with normal text)
        if best_split == -1:
            best_split = max_chunk_size
        
        chunks.append(remaining_text[:best_split].strip())
        remaining_text = remaining_text[best_split:].strip()
    
    return [chunk for chunk in chunks if chunk]  # Remove empty chunks

@contextmanager
def suppress_http_logs():
    """Temporarily suppress HTTP and service logs during health checks"""
    # Suppress uvicorn, httpx, and other HTTP-related logs
    loggers_to_suppress = [
        'uvicorn.access',
        'uvicorn.error', 
        'httpx',
        'requests.packages.urllib3.connectionpool',
        'urllib3.connectionpool'
    ]
    
    original_levels = {}
    try:
        for logger_name in loggers_to_suppress:
            logger = logging.getLogger(logger_name)
            original_levels[logger_name] = logger.level
            logger.setLevel(logging.WARNING)  # Only show warnings and errors
        yield
    finally:
        # Restore original logging levels
        for logger_name, original_level in original_levels.items():
            logging.getLogger(logger_name).setLevel(original_level)

class InteractivePipelineTester:
    """Interactive tester for specific service combinations"""
    
    def __init__(self):
        """Initialize the interactive tester"""
        self.base_dir = Path(__file__).parent
        self.audio_dir = self.base_dir / "audio_samples" / "interactive_pipeline"
        self.audio_dir.mkdir(parents=True, exist_ok=True)
        
        # All possible service endpoints
        self.all_services = {
            "orchestrator": {"url": "http://localhost:8000", "type": "orchestrator"},
            "whisper_stt": {"url": "http://localhost:8003", "type": "stt"},
            "kokoro_tts": {"url": "http://localhost:8011", "type": "tts"},
            "hira_dia_tts": {"url": "http://localhost:8012", "type": "tts"}, 
            "dia_4bit_tts": {"url": "http://localhost:8013", "type": "tts"},
            "mistral_llm": {"url": "http://localhost:8021", "type": "llm"},
            "gpt_llm": {"url": "http://localhost:8022", "type": "llm"}
        }
        
        # Track which services are available
        self.available_services = {}
        
        # Audio recording settings
        self.recording_settings = {
            'format': pyaudio.paInt16,
            'channels': 1,
            'rate': 16000,  # 16kHz for speech
            'chunk': 1024,
            'record_seconds': 5,  # Default recording duration
        }
        
    def record_microphone_audio(self, duration: int = 5) -> str:
        """Record audio from microphone and save to file"""
        print(f"ğŸ¤ Recording audio for {duration} seconds...")
        print("   Speak now...")
        
        # Initialize PyAudio
        audio = pyaudio.PyAudio()
        
        try:
            # Open microphone stream
            stream = audio.open(
                format=self.recording_settings['format'],
                channels=self.recording_settings['channels'],
                rate=self.recording_settings['rate'],
                input=True,
                frames_per_buffer=self.recording_settings['chunk']
            )
            
            frames = []
            
            # Record audio
            for i in range(0, int(self.recording_settings['rate'] / self.recording_settings['chunk'] * duration)):
                data = stream.read(self.recording_settings['chunk'])
                frames.append(data)
            
            print("âœ… Recording completed!")
            
            # Stop and close the stream
            stream.stop_stream()
            stream.close()
            
            # Save to file
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"recorded_audio_{timestamp}.wav"
            filepath = self.audio_dir / filename
            
            # Write WAV file
            with wave.open(str(filepath), 'wb') as wf:
                wf.setnchannels(self.recording_settings['channels'])
                wf.setsampwidth(audio.get_sample_size(self.recording_settings['format']))
                wf.setframerate(self.recording_settings['rate'])
                wf.writeframes(b''.join(frames))
            
            print(f"ğŸµ Audio saved: {filename}")
            return str(filepath)
            
        except Exception as e:
            print(f"âŒ Recording failed: {e}")
            return None
        finally:
            audio.terminate()
    
    def chunk_text_intelligently(self, text: str, max_chars: int = 2900) -> List[str]:
        """Split text into chunks that respect sentence boundaries"""
        if len(text) <= max_chars:
            return [text]
        
        chunks = []
        current_chunk = ""
        
        # Split by sentences first (looking for . ! ? followed by space or newline)
        import re
        sentences = re.split(r'([.!?]+(?:\s|\n|$))', text)
        
        # Recombine sentences with their punctuation
        sentence_list = []
        for i in range(0, len(sentences) - 1, 2):
            if i + 1 < len(sentences):
                sentence_list.append(sentences[i] + sentences[i + 1])
            else:
                sentence_list.append(sentences[i])
        
        for sentence in sentence_list:
            # If adding this sentence would exceed the limit
            if len(current_chunk) + len(sentence) > max_chars:
                if current_chunk:  # Save current chunk if it has content
                    chunks.append(current_chunk.strip())
                    current_chunk = sentence
                else:
                    # Single sentence too long - split by words
                    words = sentence.split()
                    temp_chunk = ""
                    for word in words:
                        if len(temp_chunk) + len(word) + 1 <= max_chars:
                            temp_chunk += (" " if temp_chunk else "") + word
                        else:
                            if temp_chunk:
                                chunks.append(temp_chunk.strip())
                            temp_chunk = word
                    if temp_chunk:
                        current_chunk = temp_chunk
            else:
                current_chunk += (" " if current_chunk else "") + sentence
        
        # Add the last chunk
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
        
    def check_service_health(self, service_name: str, endpoint: str) -> bool:
        """Check if a service is running and healthy"""
        try:
            # Try health endpoint first - disable requests logging to reduce noise
            import urllib3
            urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
            
            health_response = requests.get(f"{endpoint}/health", timeout=3)
            if health_response.status_code == 200:
                return True
        except:
            pass
        
        try:
            # Try root endpoint as fallback
            root_response = requests.get(endpoint, timeout=3)
            if root_response.status_code in [200, 404]:  # 404 is OK for some services
                return True
        except:
            pass
        
        return False
    
    def detect_available_services(self) -> Dict:
        """Detect which services are currently available"""
        print("ğŸ” Checking service availability...")
        print("-" * 40)
        
        available = {}
        
        with suppress_http_logs():  # Suppress INFO logs during health checks
            for service_name, config in self.all_services.items():
                endpoint = config["url"]
                if self.check_service_health(service_name, endpoint):
                    available[service_name] = config
                    print(f"  âœ… {service_name:<20} - {endpoint}")
                else:
                    print(f"  âŒ {service_name:<20} - Not available")
        
        self.available_services = available
        
        print(f"\nğŸ“Š Available: {len(available)} services")
        return available
    
    def select_services_by_type(self, service_type: str) -> Optional[str]:
        """Let user select a service of specific type"""
        # If no services detected at all, try to find them in the config
        if not self.available_services:
            print(f"ğŸ’¡ Attempting to find available {service_type.upper()} services...")
            potential_services = {name: config for name, config in self.all_services.items() 
                                if config["type"] == service_type}
            
            # Quick check if any are available
            for service_name, config in potential_services.items():
                if self.check_service_health(service_name, config["url"]):
                    self.available_services[service_name] = config
                    print(f"âœ… Found and selected {service_type.upper()}: {service_name}")
                    return service_name
            
            print(f"âŒ No {service_type.upper()} services are running")
            return None
        
        available_of_type = {name: config for name, config in self.available_services.items() 
                           if config["type"] == service_type}
        
        if not available_of_type:
            print(f"âŒ No {service_type.upper()} services available")
            return None
        
        if len(available_of_type) == 1:
            service_name = list(available_of_type.keys())[0]
            print(f"âœ… Auto-selected {service_type.upper()}: {service_name}")
            return service_name
        
        print(f"\nğŸ“‹ Available {service_type.upper()} services:")
        services_list = list(available_of_type.keys())
        for i, service_name in enumerate(services_list, 1):
            endpoint = available_of_type[service_name]["url"]
            print(f"  {i}. {service_name} - {endpoint}")
        
        while True:
            try:
                choice = input(f"\nSelect {service_type.upper()} service (1-{len(services_list)}): ").strip()
                if choice.isdigit():
                    idx = int(choice) - 1
                    if 0 <= idx < len(services_list):
                        selected = services_list[idx]
                        print(f"âœ… Selected {service_type.upper()}: {selected}")
                        return selected
                print(f"âŒ Please enter a number between 1 and {len(services_list)}")
            except KeyboardInterrupt:
                return None
    
    async def test_stt_to_llm(self, stt_service: str, llm_service: str) -> bool:
        """Test STT â†’ LLM pipeline component with real microphone recording"""
        print(f"\nğŸ™ï¸ Testing {stt_service} â†’ {llm_service}")
        print("-" * 50)
        
        try:
            # Option to use microphone or text input
            use_mic = input("Use microphone recording? (y/n, default=y): ").strip().lower()
            if use_mic in ['', 'y', 'yes']:
                # Record from microphone
                duration = input("Recording duration in seconds (default=5): ").strip()
                try:
                    duration = int(duration) if duration else 5
                    duration = max(1, min(duration, 30))  # Limit between 1-30 seconds
                except ValueError:
                    duration = 5
                
                print(f"\nğŸ¤ Get ready to speak in 3 seconds...")
                time.sleep(3)
                
                audio_file = self.record_microphone_audio(duration)
                if not audio_file:
                    print("âŒ Recording failed, falling back to text input")
                    test_text = input("Enter test text: ").strip() or "Hello, how are you today?"
                    print(f"ğŸ“ Using text input: '{test_text}'")
                else:
                    # Try STT service first, then direct Whisper as backup
                    print(f"ğŸ”„ Attempting transcription with recorded audio...")
                    
                    try:
                        # Send audio to STT service
                        stt_endpoint = self.available_services[stt_service]["url"]
                        print(f"ğŸ”„ Trying STT service: {stt_endpoint}")
                        
                        with open(audio_file, 'rb') as f:
                            files = {'audio': f}
                            stt_response = requests.post(f"{stt_endpoint}/transcribe", files=files, timeout=30)
                        
                        if stt_response.status_code == 200:
                            stt_result = stt_response.json()
                            test_text = stt_result.get("text", "").strip()
                            confidence = stt_result.get("confidence", 0.0)
                            
                            if test_text:
                                print(f"âœ… STT Service Success: '{test_text}' (confidence: {confidence:.2f})")
                            else:
                                print(f"âš ï¸  STT service returned empty transcript")
                                test_text = ""
                        else:
                            print(f"âŒ STT service failed: {stt_response.status_code}")
                            test_text = ""
                    
                    except Exception as e:
                        print(f"âŒ STT service error: {e}")
                        test_text = ""
                    
                    # If STT service failed or returned empty, try direct Whisper
                    if not test_text:
                        print("ğŸ”„ Trying direct Whisper transcription...")
                        try:
                            import sys
                            import os
                            
                            # Add the project root to Python path
                            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                            if project_root not in sys.path:
                                sys.path.insert(0, project_root)
                            
                            from voicebot_orchestrator.real_whisper_stt import WhisperSTT
                            
                            whisper = WhisperSTT()
                            test_text = await whisper.transcribe_file(audio_file)
                            test_text = test_text.strip() if test_text else ""
                            
                            if test_text:
                                print(f"âœ… Direct Whisper Success: '{test_text}'")
                            else:
                                print("âš ï¸  Direct Whisper also returned empty")
                                
                        except Exception as e:
                            print(f"âŒ Direct Whisper failed: {e}")
                            # Try alternative approach with simple whisper import
                            try:
                                import whisper
                                print("ğŸ”„ Trying fallback Whisper approach...")
                                
                                model = whisper.load_model("base")
                                result = model.transcribe(audio_file)
                                test_text = result["text"].strip()
                                
                                if test_text:
                                    print(f"âœ… Fallback Whisper Success: '{test_text}'")
                                else:
                                    print("âš ï¸  Fallback Whisper also returned empty")
                                    
                            except Exception as e2:
                                print(f"âŒ Fallback Whisper also failed: {e2}")
                    
                    # Final fallback if both methods failed
                    if not test_text:
                        print("âš ï¸  All transcription methods failed - using fallback")
                        test_text = "Hello, how are you today?"
            else:
                # Text input mode
                test_text = input("Enter test text (or press Enter for default): ").strip()
                if not test_text:
                    test_text = "Hello, how are you today?"
                print(f"ğŸ“ Input text: '{test_text}'")
            
            # Send to LLM
            llm_endpoint = self.available_services[llm_service]["url"]
            llm_data = {
                "text": test_text,
                "temperature": 0.7,
                "max_tokens": 150
            }
            
            print(f"ğŸ”„ Sending to LLM: {llm_endpoint}")
            
            llm_response = requests.post(f"{llm_endpoint}/generate", json=llm_data, timeout=30)
            
            if llm_response.status_code == 200:
                llm_result = llm_response.json()
                llm_text = llm_result.get("response", "").strip()
                print(f"âœ… LLM Response: '{llm_text[:200]}...'")
                return True
            else:
                print(f"âŒ LLM request failed: {llm_response.status_code}")
                print(f"   Response: {llm_response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ STTâ†’LLM test failed: {e}")
            traceback.print_exc()
            return False
    
    async def test_llm_to_tts(self, llm_service: str, tts_service: str) -> bool:
        """Test LLM â†’ TTS pipeline component"""
        print(f"\nğŸ§  Testing {llm_service} â†’ {tts_service}")
        print("-" * 50)
        
        try:
            # Get input text for LLM
            input_text = input("Enter input for LLM (or press Enter for default): ").strip()
            if not input_text:
                input_text = "Tell me a short joke"
            
            print(f"ğŸ“ LLM Input: '{input_text}'")
            
            # Send to LLM first
            llm_endpoint = self.available_services[llm_service]["url"]
            llm_data = {
                "text": input_text,
                "temperature": 0.7,
                "max_tokens": 100
            }
            
            print(f"ğŸ”„ Sending to LLM: {llm_endpoint}")
            
            llm_response = requests.post(f"{llm_endpoint}/generate", json=llm_data, timeout=30)
            if llm_response.status_code != 200:
                print(f"âŒ LLM request failed: {llm_response.status_code}")
                print(f"   Response: {llm_response.text}")
                return False
                
            llm_result = llm_response.json() 
            llm_text = llm_result.get("response", "").strip()
            print(f"âœ… LLM Output: '{llm_text[:100]}...'")
            
            # Send LLM output to TTS
            tts_endpoint = self.available_services[tts_service]["url"]
            tts_data = {
                "text": llm_text,
                "voice": "af_bella",  # Use a valid Kokoro voice instead of "default"
                "speed": 1.0,
                "return_audio": True
            }
            
            print(f"ğŸ”„ Sending to TTS: {tts_endpoint}")
            
            tts_response = requests.post(f"{tts_endpoint}/synthesize", json=tts_data, timeout=120)  # Increased for Nari Dia
            if tts_response.status_code == 200:
                tts_result = tts_response.json()
                audio_data = tts_result.get("audio_base64")
                
                if audio_data:
                    # Save audio file
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"llm_to_tts_{llm_service}_{tts_service}_{timestamp}.wav"
                    filepath = self.audio_dir / filename
                    
                    audio_bytes = base64.b64decode(audio_data)
                    with open(filepath, "wb") as f:
                        f.write(audio_bytes)
                    
                    print(f"âœ… Audio saved: {filename}")
                    return True
                else:
                    print(f"âŒ No audio data received from TTS")
                    return False
            else:
                print(f"âŒ TTS request failed: {tts_response.status_code}")
                print(f"   Response: {tts_response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ LLMâ†’TTS test failed: {e}")
            traceback.print_exc()
            return False
    
    async def test_typed_text_to_tts(self, tts_service: str) -> bool:
        """Test direct text input to TTS with unlimited timeout and custom options"""
        print(f"\nğŸ¤ Testing Typed Text â†’ {tts_service}")
        print("-" * 50)
        
        try:
            # Multi-line text input with full preview and editing capability
            print("ğŸ“ Enter your text for TTS synthesis:")
            print("   ğŸ’¡ Instructions:")
            print("      - Paste or type your text (unlimited length)")
            print("      - Press Enter after each line")
            print("      - Type 'DONE' on a new line when finished")
            print("      - Type 'CANCEL' to cancel")
            print("      - Leave empty and type 'DONE' for default text")
            print()
            
            lines = []
            line_count = 1
            
            print("ğŸ“– Enter your text (type 'DONE' when finished):")
            
            while True:
                try:
                    line = input(f"Line {line_count:2d}: ")
                    
                    if line.strip().upper() == "DONE":
                        break
                    elif line.strip().upper() == "CANCEL":
                        print("âŒ Cancelled by user")
                        return False
                    else:
                        lines.append(line)
                        line_count += 1
                        
                except KeyboardInterrupt:
                    print("\nâŒ Input cancelled.")
                    return False
                except EOFError:
                    break
            
            # Handle the text input
            if not lines:
                text_input = "Hello! This is a test of the text-to-speech system with unlimited character support. You can paste or type as much text as you want, and the system will generate high-quality speech from it. How does this sound?"
                print(f"\nğŸ“ Using default text")
            else:
                text_input = "\n".join(lines)  # Preserve line breaks
                print(f"\nğŸ“ Text entered successfully!")
            
            # Show complete text for review
            char_count = len(text_input)
            word_count = len(text_input.split())
            line_count = len(text_input.split('\n'))
            
            print(f"\nï¿½ Text Statistics:")
            print(f"   ğŸ“ Length: {char_count:,} characters")
            print(f"   ğŸ“ Words: {word_count:,}")
            print(f"   ğŸ“„ Lines: {line_count:,}")
            
            print(f"\nğŸ“– Complete Text Preview:")
            print("-" * 60)
            print(text_input)
            print("-" * 60)
            
            # Confirm before processing
            while True:
                confirm = input(f"\nâœ… Process this text? (y/n/edit): ").strip().lower()
                if confirm in ['y', 'yes']:
                    break
                elif confirm in ['n', 'no']:
                    print("âŒ Cancelled by user")
                    return False
                elif confirm in ['e', 'edit']:
                    print("ğŸ“ Edit mode not implemented yet. Please restart text entry.")
                    return False
                else:
                    print("âŒ Please enter 'y' (yes), 'n' (no), or 'edit'")
            
            if len(text_input) > 10000:  # Warn for very long text
                print(f"\nâš ï¸  Large text detected ({len(text_input):,} characters)")
                print(f"   This may take several minutes to generate")
                continue_choice = input("   Continue? (y/n): ").strip().lower()
                if continue_choice not in ['y', 'yes']:
                    print("âŒ Cancelled by user")
                    return False
            
            # Optional seed setting
            seed_input = input("\nğŸ² Enter random seed (leave empty for random): ").strip()
            if seed_input:
                try:
                    seed = int(seed_input)
                    print(f"   ğŸ² Using seed: {seed}")
                except ValueError:
                    import random
                    seed = random.randint(1, 999999)
                    print(f"   ğŸ² Invalid seed, using random: {seed}")
            else:
                import random
                seed = random.randint(1, 999999)
                print(f"   ğŸ² Using random seed: {seed}")
            
            # Optional quality setting
            quality_choice = input("\nHigh quality mode? (y/n, default=y): ").strip().lower()
            high_quality = quality_choice in ['', 'y', 'yes']
            
            # Optional speed setting  
            speed_input = input("Speech speed (0.5-2.0, default=1.0): ").strip()
            try:
                speed = float(speed_input) if speed_input else 1.0
                speed = max(0.5, min(speed, 2.0))  # Clamp between 0.5 and 2.0
            except ValueError:
                speed = 1.0
            
            print(f"\nğŸ”„ Sending to TTS: {self.available_services[tts_service]['url']}")
            print(f"   ğŸ“Š Text length: {len(text_input)} characters")
            print(f"   ğŸ¯ High quality: {high_quality}")
            print(f"   âš¡ Speed: {speed}x")
            print(f"   ğŸ² Seed: {seed}")
            print(f"   â³ No timeout limit - will wait for completion")
            
            # Prepare TTS request
            tts_endpoint = self.available_services[tts_service]["url"]
            print(f"\nğŸ”„ Sending to TTS: {tts_endpoint}")
            print(f"   ğŸ“Š Text length: {len(text_input)} characters")
            print(f"   ğŸ¯ High quality: {high_quality}")
            print(f"   âš¡ Speed: {speed}x")
            print(f"   â³ No timeout limit - will wait for completion")
            
            # Check if text needs chunking for Dia TTS
            if len(text_input) > 3000:
                print(f"\nğŸ“„ Text is {len(text_input)} characters - chunking for Dia TTS (max 3000 chars)")
                chunks = self.chunk_text_intelligently(text_input, max_chars=2900)
                print(f"   âœ‚ï¸  Split into {len(chunks)} chunks")
                
                audio_files = []
                total_generation_time = 0
                
                for i, chunk in enumerate(chunks, 1):
                    print(f"\nğŸµ Generating chunk {i}/{len(chunks)} ({len(chunk)} chars)...")
                    
                    chunk_data = {
                        "text": chunk,
                        "high_quality": high_quality,
                        "speed": speed,
                        "return_audio": True
                    }
                    
                    start_time = time.time()
                    chunk_response = requests.post(f"{tts_endpoint}/synthesize", json=chunk_data, timeout=None)
                    chunk_time = time.time() - start_time
                    total_generation_time += chunk_time
                    
                    print(f"   â±ï¸ Chunk {i} completed in {chunk_time:.1f} seconds")
                    
                    if chunk_response.status_code == 200:
                        chunk_result = chunk_response.json()
                        chunk_audio = chunk_result.get("audio_base64")
                        
                        if chunk_audio:
                            # Save individual chunk
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            safe_text = "".join(c for c in text_input[:30] if c.isalnum() or c in ' -_').strip()
                            safe_text = "_".join(safe_text.split())
                            chunk_filename = f"chunk_{i:02d}_of_{len(chunks):02d}_{safe_text}_{tts_service}_{timestamp}.wav"
                            chunk_filepath = self.audio_dir / chunk_filename
                            
                            chunk_audio_bytes = base64.b64decode(chunk_audio)
                            with open(chunk_filepath, "wb") as f:
                                f.write(chunk_audio_bytes)
                            
                            audio_files.append(chunk_filepath)
                            print(f"   âœ… Chunk {i} saved: {chunk_filename}")
                        else:
                            print(f"   âŒ No audio data for chunk {i}")
                            return False
                    else:
                        print(f"   âŒ Chunk {i} failed: {chunk_response.status_code}")
                        print(f"   Response: {chunk_response.text}")
                        return False
                
                print(f"\nğŸ‰ All chunks generated in {total_generation_time:.1f} seconds total")
                print(f"ğŸ“ Generated {len(audio_files)} audio files:")
                
                total_size = 0
                for audio_file in audio_files:
                    file_size = audio_file.stat().st_size
                    total_size += file_size
                    print(f"   ğŸ“¦ {audio_file.name} ({file_size:,} bytes)")
                
                print(f"\nğŸ“Š Total audio size: {total_size:,} bytes ({total_size/1024:.1f} KB)")
                print(f"ğŸ’¡ You can combine these files with audio editing software if needed")
                
                return True
            
            else:
                # Single chunk processing (original logic)
                tts_data = {
                    "text": text_input,
                    "high_quality": high_quality,
                    "speed": speed,
                    "seed": seed,
                    "return_audio": True
                }
                
                # Send TTS request with no timeout limit
                start_time = time.time()
                print(f"\nğŸµ Generating speech... (this may take a while for longer text)")
                
                tts_response = requests.post(f"{tts_endpoint}/synthesize", json=tts_data, timeout=None)  # No timeout!
                
                generation_time = time.time() - start_time
                print(f"â±ï¸ Generation completed in {generation_time:.1f} seconds")
                
                if tts_response.status_code == 200:
                    tts_result = tts_response.json()
                    audio_data = tts_result.get("audio_base64")
                    duration = tts_result.get("duration", "unknown")
                    
                    if audio_data:
                        # Save audio file with descriptive name
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        # Create safe filename from first few words
                        safe_text = "".join(c for c in text_input[:30] if c.isalnum() or c in ' -_').strip()
                        safe_text = "_".join(safe_text.split())
                        filename = f"custom_text_{safe_text}_seed_{seed}_{tts_service}_{timestamp}.wav"
                        filepath = self.audio_dir / filename
                        
                        audio_bytes = base64.b64decode(audio_data)
                        with open(filepath, "wb") as f:
                            f.write(audio_bytes)
                        
                        print(f"âœ… Audio saved: {filename}")
                        print(f"ğŸ“Š Audio duration: {duration} seconds")
                        print(f"ğŸ“ Saved to: {filepath}")
                        
                        # Optional: Play audio info
                        file_size = len(audio_bytes)
                        print(f"ğŸ“¦ File size: {file_size:,} bytes ({file_size/1024:.1f} KB)")
                        
                        return True
                    else:
                        print(f"âŒ No audio data received from TTS")
                        return False
                else:
                    print(f"âŒ TTS request failed: {tts_response.status_code}")
                    print(f"   Response: {tts_response.text}")
                    return False
                
        except Exception as e:
            print(f"âŒ Typed Textâ†’TTS test failed: {e}")
            traceback.print_exc()
            return False
    
    async def test_full_pipeline(self, stt_service: str, llm_service: str, tts_service: str) -> bool:
        """Test complete STT â†’ LLM â†’ TTS pipeline with real microphone recording"""
        print(f"\nğŸ¯ Testing Full Pipeline: {stt_service} â†’ {llm_service} â†’ {tts_service}")
        print("-" * 70)
        
        try:
            # Option to use microphone or text input
            use_mic = input("Use microphone for STT input? (y/n, default=y): ").strip().lower()
            
            if use_mic in ['', 'y', 'yes']:
                # Record from microphone
                duration = input("Recording duration in seconds (default=5): ").strip()
                try:
                    duration = int(duration) if duration else 5
                    duration = max(1, min(duration, 30))  # Limit between 1-30 seconds
                except ValueError:
                    duration = 5
                
                print(f"\nğŸ¤ Get ready to speak in 3 seconds...")
                time.sleep(3)
                
                audio_file = self.record_microphone_audio(duration)
                if not audio_file:
                    print("âŒ Recording failed, falling back to text input")
                    input_text = input("Enter test input: ").strip() or "What's the weather like today?"
                    print(f"ğŸ“ Using text input: '{input_text}'")
                else:
                    # Send audio to STT service
                    stt_endpoint = self.available_services[stt_service]["url"]
                    
                    print(f"ğŸ”„ Step 1 - STT Processing: {stt_endpoint}")
                    
                    with open(audio_file, 'rb') as f:
                        files = {'audio': f}
                        stt_response = requests.post(f"{stt_endpoint}/transcribe", files=files, timeout=30)
                    
                    if stt_response.status_code == 200:
                        stt_result = stt_response.json()
                        input_text = stt_result.get("text", "").strip()  # Changed from "transcript" to "text"
                        confidence = stt_result.get("confidence", 0.0)
                        print(f"âœ… STT Transcript: '{input_text}' (confidence: {confidence:.2f})")
                        
                        if not input_text:
                            print("âŒ Empty transcript from STT service!")
                            print("ğŸ”„ Attempting direct Whisper transcription...")
                            
                            # Try direct Whisper transcription as fallback
                            try:
                                import sys
                                import os
                                
                                # Add the project root to Python path
                                project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
                                if project_root not in sys.path:
                                    sys.path.insert(0, project_root)
                                
                                from voicebot_orchestrator.real_whisper_stt import WhisperSTT
                                
                                whisper = WhisperSTT()
                                input_text = await whisper.transcribe_file(audio_file)
                                input_text = input_text.strip() if input_text else ""
                                
                                if input_text:
                                    print(f"âœ… Direct Whisper Result: '{input_text}'")
                                else:
                                    print("âš ï¸  Direct Whisper also returned empty")
                                    
                            except Exception as e:
                                print(f"âŒ Direct Whisper failed: {e}")
                                # Try alternative approach with simple whisper import
                                try:
                                    import whisper
                                    print("ğŸ”„ Trying fallback Whisper approach...")
                                    
                                    model = whisper.load_model("base")
                                    result = model.transcribe(audio_file)
                                    input_text = result["text"].strip()
                                    
                                    if input_text:
                                        print(f"âœ… Fallback Whisper Success: '{input_text}'")
                                    else:
                                        print("âš ï¸  Even fallback Whisper returned empty - using minimal fallback")
                                        input_text = "What's the weather like today?"
                                        
                                except Exception as e2:
                                    print(f"âŒ Fallback Whisper also failed: {e2}")
                                    print("âš ï¸  Using fallback text")
                                    input_text = "What's the weather like today?"
                    else:
                        print(f"âŒ STT step failed: {stt_response.status_code}")
                        print(f"   Response: {stt_response.text}")
                        print("   Using fallback text")
                        input_text = "What's the weather like today?"
            else:
                # Text input mode
                input_text = input("Enter test input (or press Enter for default): ").strip()
                if not input_text:
                    input_text = "What's the weather like today?"
                print(f"ğŸ™ï¸ STT Input (text mode): '{input_text}'")
            
            # Step 2: LLM Processing
            llm_endpoint = self.available_services[llm_service]["url"]
            llm_data = {
                "text": input_text,
                "temperature": 0.7,
                "max_tokens": 150
            }
            
            print(f"ğŸ”„ Step 2 - LLM Processing: {llm_endpoint}")
            
            llm_response = requests.post(f"{llm_endpoint}/generate", json=llm_data, timeout=30)
            if llm_response.status_code != 200:
                print(f"âŒ LLM step failed: {llm_response.status_code}")
                print(f"   Response: {llm_response.text}")
                return False
                
            llm_result = llm_response.json()
            llm_text = llm_result.get("response", "").strip()
            print(f"âœ… LLM Output: '{llm_text[:100]}...'")
            
            # Step 2: TTS Synthesis
            tts_endpoint = self.available_services[tts_service]["url"]
            tts_data = {
                "text": llm_text,
                "voice": "af_bella",  # Use a valid Kokoro voice instead of "default"
                "speed": 1.0,
                "return_audio": True
            }
            
            print(f"ğŸ”„ Step 2 - TTS Synthesis: {tts_endpoint}")
            
            tts_response = requests.post(f"{tts_endpoint}/synthesize", json=tts_data, timeout=120)  # Increased for Nari Dia
            if tts_response.status_code == 200:
                tts_result = tts_response.json()
                audio_data = tts_result.get("audio_base64")
                
                if audio_data:
                    # Save audio file
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    safe_name = f"{stt_service}_{llm_service}_{tts_service}"
                    filename = f"full_pipeline_{safe_name}_{timestamp}.wav"
                    filepath = self.audio_dir / filename
                    
                    audio_bytes = base64.b64decode(audio_data)
                    with open(filepath, "wb") as f:
                        f.write(audio_bytes)
                    
                    print(f"âœ… Complete Pipeline Success! Audio saved: {filename}")
                    return True
                else:
                    print(f"âŒ No audio generated")
                    return False
            else:
                print(f"âŒ TTS step failed: {tts_response.status_code}")
                print(f"   Response: {tts_response.text}")
                return False
                
        except Exception as e:
            print(f"âŒ Full pipeline test failed: {e}")
            traceback.print_exc()
            return False
    
    async def test_direct_dia_tts(self) -> bool:
        """Test direct Dia TTS model with EOS analysis and optimizations"""
        print("\nğŸ¯ Direct Dia TTS Test with EOS Analysis")
        print("-" * 50)
        
        try:
            import sys
            import os
            import torch
            import soundfile as sf
            import time
            import numpy as np
            import random
            from datetime import datetime
            import gc
            
            # Check if we're in the right directory for Dia
            current_dir = os.getcwd()
            tests_dia_path = os.path.join(current_dir, "tests", "dia")
            
            if not os.path.exists(tests_dia_path):
                print(f"âŒ Dia model directory not found: {tests_dia_path}")
                print(f"   Current directory: {current_dir}")
                print(f"   Please run from the main Orkestra directory")
                return False
            
            # Apply GPU optimizations
            print("ğŸš€ Applying GPU optimizations...")
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.backends.cudnn.benchmark = True
                torch.backends.cudnn.deterministic = False
                torch.cuda.set_per_process_memory_fraction(0.7)
                print("   âœ… GPU optimizations applied")
            else:
                print("   âš ï¸ CUDA not available, using CPU")
            
            # Load Dia model
            print("ğŸ“¥ Loading Dia model...")
            original_dir = os.getcwd()
            os.chdir(tests_dia_path)
            
            sys.path.insert(0, tests_dia_path)
            from dia.model import Dia
            
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            # Load model with memory management
            torch.cuda.empty_cache() if torch.cuda.is_available() else None
            model = Dia.from_pretrained("nari-labs/Dia-1.6B-0626", device=device)
            print(f"âœ… Model loaded on {device}")
            
            # Show GPU status
            if torch.cuda.is_available():
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                gpu_allocated = torch.cuda.memory_allocated(0) / 1024**3
                gpu_reserved = torch.cuda.memory_reserved(0) / 1024**3
                print(f"ğŸ“Š GPU Memory: {gpu_allocated:.1f}GB allocated, {gpu_reserved:.1f}GB reserved of {gpu_memory:.1f}GB total")
            
            # Get user input for text
            print("\nğŸ“ TEXT INPUT")
            print("=" * 30)
            print("Enter your text (type 'DONE' on a new line to finish):")
            print("Or press Enter for default Alex/Payoff Debt text")
            
            user_lines = []
            first_line = input("> ").strip()
            
            if first_line == "":
                # Use default text
                test_text = """Hello, hello! This is Alex calling with Finally Payoff Debt, your pre-qualification specialist. (laughs) I'm so glad you picked up today. (clears throat) I promise this will be quick, and helpful.
Here's the news: We've rolled out new income-based loan options to help people escape high-interest credit cards and personal loans. (sighs) You know the onesâ€”you pay and pay, but the balance never drops.
Now, listenâ€¦ (gasps) if you've got steady income, we can help you qualify for a personal loan between ten thousand and one hundred thousand dollars. (coughs) That means instead of juggling multiple bills, you could roll them into one easy payment."""
                print("ğŸ“– Using default Alex/Payoff Debt text")
            elif first_line.upper() == "DONE":
                print("âŒ No text entered!")
                return False
            else:
                user_lines.append(first_line)
                
                while True:
                    line = input("> ").strip()
                    if line.upper() == "DONE":
                        break
                    user_lines.append(line)
                
                test_text = "\n".join(user_lines)
                print(f"ğŸ“– Custom text entered ({len(user_lines)} lines)")
            
            # Format and show text
            formatted_text = f"[S1] {test_text.replace('â†’', '->')}"  # Unicode fix + Dia format
            print(f"\nğŸ“Š Text Analysis:")
            print(f"   Characters: {len(test_text)}")
            print(f"   Lines: {test_text.count(chr(10)) + 1}")
            print(f"   Words (approx): {len(test_text.split())}")
            
            # Get user input for seed
            print("\nğŸ² SEED SELECTION")
            print("=" * 30)
            seed_input = input("Enter seed number (or press Enter for random): ").strip()
            
            if seed_input == "":
                user_seed = random.randint(1000, 99999)
                print(f"ğŸ² Random seed generated: {user_seed}")
            else:
                try:
                    user_seed = int(seed_input)
                    print(f"ğŸ² Using seed: {user_seed}")
                except ValueError:
                    print("âŒ Invalid seed, using random")
                    user_seed = random.randint(1000, 99999)
                    print(f"ğŸ² Random seed generated: {user_seed}")
            
            # Get token count preference with realistic time estimates
            print("\nğŸ”§ TOKEN CONFIGURATION")
            print("=" * 30)
            print("Available options (with realistic time estimates):")
            print("1. ğŸš€ Quick test (2048 tokens ~ 10-12 minutes)")
            print("2. âš–ï¸ Medium test (8192 tokens ~ 40-48 minutes)")
            print("3. ğŸ¯ Long test (16384 tokens ~ 80-96 minutes)")
            print("4. ğŸ¨ Custom amount")
            print("5. ğŸ’¡ Speed test (1024 tokens ~ 5-6 minutes)")
            
            choice = input("Choose option (1-5, default=1 for speed): ").strip()
            
            if choice == "1" or choice == "":
                token_count = 2048
                est_minutes = 11
                print("ğŸš€ Quick test selected")
            elif choice == "2":
                token_count = 8192
                est_minutes = 44
                print("âš–ï¸ Medium test selected")
                confirm = input(f"âš ï¸ This will take ~{est_minutes} minutes. Continue? (y/N): ").strip().lower()
                if confirm != 'y':
                    token_count = 2048
                    est_minutes = 11
                    print("ğŸš€ Switched to quick test")
            elif choice == "3":
                token_count = 16384
                est_minutes = 88
                print("ğŸ¯ Long test selected")
                confirm = input(f"âš ï¸ This will take ~{est_minutes} minutes. Continue? (y/N): ").strip().lower()
                if confirm != 'y':
                    token_count = 2048
                    est_minutes = 11
                    print("ğŸš€ Switched to quick test")
            elif choice == "4":
                custom_tokens = input("Enter custom token count (512-65536): ").strip()
                try:
                    token_count = int(custom_tokens)
                    if token_count < 512:
                        print("âš ï¸ Minimum 512 tokens")
                        token_count = 512
                    elif token_count > 65536:
                        print("âš ï¸ Maximum 65536 tokens")
                        token_count = 65536
                    
                    # Estimate time: ~295 seconds per 1000 tokens (based on recent tests)
                    est_minutes = (token_count / 1000) * 295 / 60
                    
                    if est_minutes > 30:
                        confirm = input(f"âš ï¸ Custom test will take ~{est_minutes:.0f} minutes. Continue? (y/N): ").strip().lower()
                        if confirm != 'y':
                            token_count = 2048
                            est_minutes = 11
                            print("ğŸš€ Switched to quick test")
                    
                    print(f"ğŸ¨ Custom test: {token_count} tokens (~{est_minutes:.0f} minutes)")
                except ValueError:
                    print("âŒ Invalid token count, using quick test")
                    token_count = 2048
                    est_minutes = 11
            elif choice == "5":
                token_count = 1024
                est_minutes = 5
                print("ğŸ’¡ Speed test selected")
            else:
                token_count = 2048
                est_minutes = 11
                print("ğŸš€ Default quick test selected")
            
            print(f"\nâ±ï¸ ESTIMATED TIME: ~{est_minutes} minutes")
            
            # Final confirmation for longer tests
            if est_minutes > 15:
                confirm = input(f"\nâš ï¸ This will take approximately {est_minutes} minutes. Continue? (y/N): ").strip().lower()
                if confirm != 'y':
                    print("âŒ Test cancelled by user")
                    return False
            
            # Set seed and run generation
            print(f"\nğŸ”„ STARTING GENERATION")
            print("=" * 50)
            
            torch.manual_seed(user_seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(user_seed)
            
            print(f"ğŸ“Š Configuration:")
            print(f"   Seed: {user_seed}")
            print(f"   Tokens: {token_count}")
            print(f"   Expected time: ~{est_minutes} minutes")
            
            print(f"\nğŸ”„ Generating audio with GPU optimizations...")
            start_time = time.time()
            
            try:
                with torch.no_grad():  # Save memory
                    audio = model.generate(
                        text=formatted_text,
                        max_tokens=token_count,
                        cfg_scale=3.0,
                        temperature=1.2,
                        top_p=0.95,
                        verbose=True  # Shows EOS analysis
                    )
                
                generation_time = time.time() - start_time
                
                # Clear cache after generation
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # Analyze results
                if hasattr(audio, 'shape') and len(audio.shape) > 0:
                    actual_duration = len(audio) / 44100
                    samples = len(audio)
                    
                    # Format times
                    gen_hours = int(generation_time // 3600)
                    gen_minutes = int((generation_time % 3600) // 60)
                    gen_seconds = int(generation_time % 60)
                    gen_time_str = f"{gen_hours:02d}:{gen_minutes:02d}:{gen_seconds:02d}"
                    
                    print(f"\nğŸ“Š RESULTS:")
                    print(f"   ğŸµ Generated duration: {actual_duration:.2f} seconds")
                    print(f"   ğŸ”¢ Audio samples: {samples:,}")
                    print(f"   â±ï¸ Generation time: {gen_time_str}")
                    print(f"   ğŸ¯ Tokens used: {token_count}")
                    print(f"   ğŸ“ˆ Performance: {token_count/generation_time:.1f} tokens/sec")
                    print(f"   âš¡ Efficiency: {actual_duration/generation_time:.3f} audio_sec/gen_sec")
                    
                    # Save file in the audio directory
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"direct_dia_seed_{user_seed}_tokens_{token_count}_{timestamp}.wav"
                    
                    # Change back to original directory for saving
                    os.chdir(original_dir)
                    filepath = self.audio_dir / filename
                    sf.write(filepath, audio, 44100)
                    print(f"   ğŸ’¾ Saved: {filename}")
                    
                    # Quality analysis
                    max_amplitude = np.max(np.abs(audio))
                    rms = np.sqrt(np.mean(audio**2))
                    
                    if rms > 0.15:
                        voice_type = "Strong/Confident"
                    elif rms > 0.10:
                        voice_type = "Normal/Balanced"
                    else:
                        voice_type = "Soft/Quiet"
                    
                    print(f"   ğŸ­ Voice character: {voice_type}")
                    print(f"   ğŸ”‰ Audio quality: Max={max_amplitude:.3f}, RMS={rms:.3f}")
                    
                    # Performance comparison with estimate
                    time_ratio = generation_time / (est_minutes * 60)
                    
                    if time_ratio < 0.8:
                        print(f"   ğŸš€ Faster than expected! ({time_ratio:.2f}x estimated)")
                    elif time_ratio > 1.2:
                        print(f"   ğŸŒ Slower than expected ({time_ratio:.2f}x estimated)")
                    else:
                        print(f"   âœ… Performance as expected ({time_ratio:.2f}x estimated)")
                    
                    # EOS Analysis summary
                    expected_duration = token_count / 1000
                    efficiency_ratio = actual_duration / expected_duration if expected_duration > 0 else 0
                    
                    print(f"\nğŸ”š EOS ANALYSIS SUMMARY:")
                    print(f"   ğŸ“Š Token efficiency: {token_count} tokens â†’ {actual_duration:.1f}s audio")
                    print(f"   ğŸ“ˆ Audio/token ratio: {efficiency_ratio:.2f}x expected")
                    
                    if efficiency_ratio < 0.5:
                        print(f"   ğŸ“‰ Early EOS detected - audio shorter than expected")
                    elif efficiency_ratio > 1.5:
                        print(f"   ğŸ“ˆ Extended generation - audio longer than expected")
                    else:
                        print(f"   âœ… Normal EOS behavior - audio length as expected")
                    
                    print(f"\nâœ… Direct Dia TTS test completed successfully!")
                    print(f"   ğŸµ Audio file: {filename}")
                    print(f"   ğŸ“Š Duration: {actual_duration:.2f}s")
                    print(f"   ğŸ­ Voice: {voice_type}")
                    
                    return True
                    
                else:
                    print(f"   âŒ No audio generated")
                    return False
            
            except KeyboardInterrupt:
                print(f"\nâš ï¸ Generation interrupted by user")
                return False
            except Exception as e:
                print(f"   âŒ Generation failed: {e}")
                import traceback
                traceback.print_exc()
                return False
                
        except Exception as e:
            print(f"âŒ Direct Dia TTS test failed: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            # Restore original directory
            try:
                os.chdir(original_dir)
            except:
                pass
    
    async def run_interactive_tests(self):
        """Run interactive test menu without automatic service checks"""
        print("ğŸ¯ Interactive Pipeline Tester")
        
        while True:
            print("\n" + "="*50)
            print("ğŸ“‹ TEST MENU")
            print("="*50)
            print("1. Test STT â†’ LLM (select specific services)")
            print("2. Test LLM â†’ TTS (select specific services)")
            print("3. Test Full Pipeline STT â†’ LLM â†’ TTS")
            print("4. Test Typed Text â†’ TTS (custom text input)")
            print("5. Check service availability")
            print("6. Show available services")
            print("7. Test Direct Dia TTS (with EOS analysis)")
            print("0. Exit")
            
            try:
                choice = input("\nSelect test type (0-7): ").strip()
                
                if choice == "0":
                    print("ğŸ‘‹ Goodbye!")
                    break
                
                elif choice == "1":
                    print("\nğŸ™ï¸ STT â†’ LLM Test")
                    # Check services first for this test
                    self.detect_available_services()
                    stt_service = self.select_services_by_type("stt")
                    if not stt_service:
                        continue
                    llm_service = self.select_services_by_type("llm")
                    if not llm_service:
                        continue
                    
                    success = await self.test_stt_to_llm(stt_service, llm_service)
                    result = "âœ… SUCCESS" if success else "âŒ FAILED"
                    print(f"\nğŸ“Š Result: {result}")
                
                elif choice == "2":
                    print("\nğŸ§  LLM â†’ TTS Test")
                    # Check services first for this test
                    self.detect_available_services()
                    llm_service = self.select_services_by_type("llm")
                    if not llm_service:
                        continue
                    tts_service = self.select_services_by_type("tts")
                    if not tts_service:
                        continue
                    
                    success = await self.test_llm_to_tts(llm_service, tts_service)
                    result = "âœ… SUCCESS" if success else "âŒ FAILED"
                    print(f"\nğŸ“Š Result: {result}")
                
                elif choice == "3":
                    print("\nğŸ¯ Full Pipeline Test")
                    # Check services first for this test
                    self.detect_available_services()
                    stt_service = self.select_services_by_type("stt")
                    if not stt_service:
                        continue
                    llm_service = self.select_services_by_type("llm")
                    if not llm_service:
                        continue
                    tts_service = self.select_services_by_type("tts")
                    if not tts_service:
                        continue
                    
                    success = await self.test_full_pipeline(stt_service, llm_service, tts_service)
                    result = "âœ… SUCCESS" if success else "âŒ FAILED"
                    print(f"\nğŸ“Š Result: {result}")
                
                elif choice == "4":
                    print("\nğŸ¤ Typed Text â†’ TTS Test")
                    # Direct to TTS service selection without any service checks
                    tts_service = self.select_services_by_type("tts")
                    if not tts_service:
                        print("âŒ No TTS services available. Use option 5 to check service status.")
                        continue
                    
                    success = await self.test_typed_text_to_tts(tts_service)
                    result = "âœ… SUCCESS" if success else "âŒ FAILED"
                    print(f"\nğŸ“Š Result: {result}")
                
                elif choice == "5":
                    print("\nï¿½ Checking service availability...")
                    self.detect_available_services()
                    print("\nï¿½ğŸ“‹ Available Services:")
                    if not self.available_services:
                        print("  âŒ No services available")
                    else:
                        for service_name, config in self.available_services.items():
                            service_type = config["type"].upper()
                            url = config["url"]
                            print(f"  âœ… {service_name:<20} ({service_type:<3}) - {url}")
                
                elif choice == "6":
                    print("\nğŸ“‹ Available Services:")
                    if not self.available_services:
                        print("  âŒ No services detected (use option 5 to check)")
                        print("  ğŸ’¡ Use option 5 to check service availability first")
                    else:
                        for service_name, config in self.available_services.items():
                            service_type = config["type"].upper()
                            url = config["url"]
                            print(f"  âœ… {service_name:<20} ({service_type:<3}) - {url}")
                
                elif choice == "7":
                    print("\nğŸ¯ Direct Dia TTS Test with EOS Analysis")
                    success = await self.test_direct_dia_tts()
                    result = "âœ… SUCCESS" if success else "âŒ FAILED"
                    print(f"\nğŸ“Š Result: {result}")
                
                else:
                    print("âŒ Invalid choice. Please enter 0-7.")
                
                if choice in ["1", "2", "3", "4", "7"]:
                    input("\nPress Enter to continue...")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Goodbye!")
                break
            except Exception as e:
                print(f"âŒ Error: {e}")
                traceback.print_exc()
                input("\nPress Enter to continue...")

async def main():
    """Main function"""
    tester = InteractivePipelineTester()
    await tester.run_interactive_tests()

if __name__ == "__main__":
    asyncio.run(main())
