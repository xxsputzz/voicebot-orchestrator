#!/usr/bin/env python3
"""
Complete WebSocket Test - Test the full WebSocket pipeline
"""
import asyncio
import websockets
import json
import time
import requests

async def test_websocket_pipeline():
    """Test the complete WebSocket pipeline"""
    print("üß™ Complete WebSocket Pipeline Test")
    print("="*50)
    
    # Step 1: Check WebSocket orchestrator
    print("1Ô∏è‚É£ Checking WebSocket Orchestrator...")
    try:
        response = requests.get("http://localhost:8080/services", timeout=3)
        if response.status_code == 200:
            services = response.json()
            print(f"   ‚úÖ Orchestrator running - Services: {services}")
        else:
            print(f"   ‚ùå Orchestrator unhealthy: {response.status_code}")
            return False
    except Exception as e:
        print(f"   ‚ùå Orchestrator not accessible: {e}")
        return False
    
    # Step 2: Check HTTP services are still running
    print("\n2Ô∏è‚É£ Checking HTTP Services...")
    http_services = [
        ("Orchestrator", 8000),
        ("Whisper STT", 8003),
        ("GPT LLM", 8022),
        ("Zonos TTS", 8014)
    ]
    
    running_services = []
    for name, port in http_services:
        try:
            response = requests.get(f"http://localhost:{port}/health", timeout=2)
            if response.status_code == 200:
                print(f"   ‚úÖ {name} running on port {port}")
                running_services.append((name, port))
            else:
                print(f"   ‚ö†Ô∏è {name} unhealthy on port {port}")
        except Exception as e:
            print(f"   ‚ùå {name} not running: {e}")
    
    # Step 3: Start WebSocket service
    print(f"\n3Ô∏è‚É£ Starting WebSocket LLM Service...")
    import subprocess
    try:
        llm_process = subprocess.Popen(
            ["python", "aws_microservices/ws_llm_gpt_service.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            creationflags=subprocess.CREATE_NEW_PROCESS_GROUP if hasattr(subprocess, 'CREATE_NEW_PROCESS_GROUP') else 0
        )
        print(f"   üöÄ Started WebSocket LLM service (PID: {llm_process.pid})")
        
        # Wait for registration
        print("   ‚è≥ Waiting for service registration...")
        await asyncio.sleep(5)
        
        # Check if registered
        response = requests.get("http://localhost:8080/services", timeout=3)
        if response.status_code == 200:
            services = response.json()
            if services:
                print(f"   ‚úÖ Services registered: {[s.get('service_id', s) for s in services]}")
            else:
                print(f"   ‚ö†Ô∏è No services registered yet")
        
    except Exception as e:
        print(f"   ‚ùå Failed to start WebSocket service: {e}")
        return False
    
    # Step 4: Test WebSocket connection
    print(f"\n4Ô∏è‚É£ Testing WebSocket Connection...")
    try:
        # Connect to CLIENT port 9000 (not service port 9001)
        websocket = await websockets.connect("ws://localhost:9000")
        print("   ‚úÖ WebSocket connection established")
        
        # Wait for welcome message from orchestrator
        welcome = await websocket.recv()
        welcome_data = json.loads(welcome)
        print(f"   ‚úÖ Welcome message: {welcome_data.get('type')}")
        session_id = welcome_data.get('session_id')
        
        # Send test message using proper session_id
        test_message = {
            "type": "conversation_start",
            "session_id": session_id,
            "timestamp": time.time(),
            "data": {"message": "Hello WebSocket"}
        }
        
        await websocket.send(json.dumps(test_message))
        print("   üì§ Sent conversation start message")
        
        # Wait for response
        try:
            response = await asyncio.wait_for(websocket.recv(), timeout=10.0)
            print(f"   üì• Received: {response}")
        except asyncio.TimeoutError:
            print("   ‚è±Ô∏è No response received (timeout)")
        
        await websocket.close()
        
    except Exception as e:
        print(f"   ‚ùå WebSocket connection failed: {e}")
    
    # Step 5: Test HTTP vs WebSocket comparison
    print(f"\n5Ô∏è‚É£ HTTP vs WebSocket Performance...")
    
    if ("GPT LLM", 8022) in running_services:
        # Test HTTP call
        print("   üîç Testing HTTP call to warm LLM service...")
        try:
            start_time = time.time()
            http_response = requests.post(
                "http://localhost:8022/chat",
                json={"message": "Hello", "session_id": "test_http"},
                timeout=10
            )
            http_time = (time.time() - start_time) * 1000
            
            if http_response.status_code == 200:
                print(f"   ‚úÖ HTTP call: {http_time:.1f}ms")
            else:
                print(f"   ‚ö†Ô∏è HTTP call status: {http_response.status_code}")
                
        except Exception as e:
            print(f"   ‚ùå HTTP call failed: {e}")
    
    # Step 6: Architecture Analysis
    print(f"\n6Ô∏è‚É£ Architecture Analysis...")
    print("   üèóÔ∏è Your Hybrid Architecture:")
    print(f"   ‚Ä¢ HTTP Services: {len(running_services)} running (always warm)")
    print("   ‚Ä¢ WebSocket Layer: Available for streaming")
    print("   ‚Ä¢ Result: Best of both worlds")
    
    print(f"\nüí° WebSocket Benefits:")
    print("   ‚úÖ Persistent connections for conversations")
    print("   ‚úÖ Real-time streaming capability")
    print("   ‚úÖ Lower per-message overhead")
    print("   ‚úÖ Connects to your warm HTTP services")
    
    # Cleanup
    try:
        llm_process.terminate()
        print(f"\nüßπ Cleaned up WebSocket service")
    except:
        pass
    
    return True

async def main():
    await test_websocket_pipeline()

if __name__ == "__main__":
    asyncio.run(main())
